# [World Models](https://arxiv.org/pdf/1803.10122.pdf)

##### TL;DR

###### Idea:

By combining vision, memory, and control models, the agents can train with much larger networks than regular RL networks. That means, this world models have much more parameters to represent data. Also they have trained evolution strategies instead of reinforcement learning in control module. They have experimented with `car-racing` and `vizdoom` environments.

###### Combined model:

![alt_text](./20180618_world_models/agent_model.png)

![alt_text](./20180618_world_models/v-m-c.png)

###### Vision:

![alt_text](./20180618_world_models/vision.png)

###### Memory:

![alt_text](./20180618_world_models/memory.png)

###### Experiments:

![alt_text](./20180618_world_models/carracing-result.png)

![alt_text](./20180618_world_models/vizdoom-result.png)

###### And more:

In the last section of this paper, they have provided interesting articles (most of them are Schumidhuber's). They are definitely worth to read!!
